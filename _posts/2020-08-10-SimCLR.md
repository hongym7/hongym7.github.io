---
title: "A Simple Framework for Contrastive Learning of Visual Representations"
date: 2020-08-10 14:00:00 -0400
categories: Terms
tags: [SimCLR, UnsupervisedLearning]
---

   
### Contrastive Learning  

<img src="/assets/img/SimCLR_01.png" width="100%"/>  
*출처 : <https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html>*

{% capture fig_img %} ![Foo]({{ '/assets/img/SimCLR_01.png' | relative_url }}) {% endcapture %}

{{ fig_img | markdownify | remove: "
" | remove: "
" }} <https://ankeshanand.com/blog/2020/01/26/contrative-self-supervised-learning.html>
  
- 두 이미지를 input으로 넣고 두 이미지가 비슷한지/아닌지를 학습시킴  
- input으로 넣을 이미지를 라벨링하는 방법은 1. 직접 수동으로 하는 방법 2. augmentation을 이용해서 자동으로 하는 방법
  
### SimCLR ?  
- Unsupervised Learning 의 한 종류. Supervised Learning의 top-1 accuracy 에 근접. Contrastive Learning 
- input image 라벨링을 위해 총 3 가지 augmentaion **(Random Crop, Color Distortions, Gaussian blur)** 사용  
    - augmentation을 실험을 통해 선정, AutoAug와 같은 복잡한 augmentation은 오히려 성능을 떨어뜨렸다. 
- Resnet 50가 encoder로 사용 되었으며 GAP Layer의 output을 사용 (2048-dimension)
- 그 뒤에 2개의 MLP(Multi Level Perceptron) 사용 (128-dimensional latent space)  
  * latent space 참고 사이트 : <https://dev-hani.tistory.com/entry/Latent-space-%EA%B0%84%EB%8B%A8-%EC%A0%95%EB%A6%AC>  
- 두 input image 간의 비슷한지/아닌지를 체크하기 위해 Cosine Similarity Function 사용  
- Normalized temperature-scaled cross entropy(NT-Xent) loss is used

#### Train
- 위에서 설명한 것과 같이 네트워크를 구성하며, 이를 학습시킴

#### How to Use?
<img src="/assets/img/SimCLR_02.png" width="90%"/>  
###### 이미지 출처 : <https://amitness.com/2020/03/illustrated-simclr/>
- **GAP Layer의 output에 layer를 붙여서 fine-tune 진행**
